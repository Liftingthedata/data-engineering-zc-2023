{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce80669",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "- 3.3.2\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42ee404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4260457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/07 10:19:01 WARN Utils: Your hostname, LAPTOP-028FK3OH resolves to a loopback address: 127.0.1.1; using 192.168.26.176 instead (on interface eth0)\n",
      "23/03/07 10:19:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/07 10:19:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90dfcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.26.176:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6e65c0b940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917597e",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "We will use this dataset for all the remaining questions.</br>\n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.</br>\n",
    "\n",
    "\n",
    "- 2MB\n",
    "- 24MB\n",
    "- 100MB\n",
    "- 250MB\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c25f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-07 10:22:05--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230307T082205Z&X-Amz-Expires=300&X-Amz-Signature=33fa188eddffd535a5afac6b26d29de0846acb739a102e49fca932764cf58f32&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-07 10:22:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230307T082205Z&X-Amz-Expires=300&X-Amz-Signature=33fa188eddffd535a5afac6b26d29de0846acb739a102e49fca932764cf58f32&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 175799316 (168M) [application/octet-stream]\n",
      "Saving to: ‘fhvhv_tripdata_2021-06.csv.gz’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 167.66M  3.41MB/s    in 50s     \n",
      "\n",
      "2023-03-07 10:22:56 (3.39 MB/s) - ‘fhvhv_tripdata_2021-06.csv.gz’ saved [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be7d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = t.StructType([\n",
    "    t.StructField('dispatching_base_num', t.StringType(), True), \n",
    "    t.StructField('pickup_datetime', t.TimestampType(), True), \n",
    "    t.StructField('dropoff_datetime', t.TimestampType(), True), \n",
    "    t.StructField('PULocationID', t.IntegerType(), True), \n",
    "    t.StructField('DOLocationID', t.IntegerType(), True), \n",
    "    t.StructField('SR_Flag', t.StringType(), True), \n",
    "    t.StructField('Affiliated_base_number', t.StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5549d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02764|2021-06-01 00:02:41|2021-06-01 00:07:46|         174|          18|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:16:16|2021-06-01 00:21:14|          32|         254|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:27:01|2021-06-01 00:42:11|         240|         127|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:46:08|2021-06-01 00:53:45|         127|         235|      N|                B02764|\n",
      "|              B02510|2021-06-01 00:45:42|2021-06-01 01:03:33|         144|         146|      N|                  null|\n",
      "|              B02510|2021-06-01 00:18:15|2021-06-01 00:25:47|          49|          17|      N|                  null|\n",
      "|              B02510|2021-06-01 00:33:06|2021-06-01 00:42:46|          49|         225|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:27|2021-06-01 00:56:50|         225|         177|      N|                  null|\n",
      "|              B02764|2021-06-01 00:48:06|2021-06-01 01:04:10|         209|          45|      N|                B02764|\n",
      "|              B02875|2021-06-01 00:18:54|2021-06-01 00:26:14|          80|         256|      N|                B02875|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3786627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                        (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/07 10:24:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/03/07 10:24:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/03/07 10:24:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/03/07 10:24:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/03/07 10:24:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/03/07 10:24:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/03/07 10:24:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/03/07 10:24:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/03/07 10:24:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(12) \\\n",
    "    .write \\\n",
    "    .parquet('fhvhv/2021/06/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba29ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mfhvhv/2021/06/\u001b[00m\r\n",
      "├── [ 24M]  part-00000-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00001-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00002-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00003-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00004-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00005-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00006-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00007-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00008-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00009-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00010-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "├── [ 24M]  part-00011-5f8a3c77-ec31-48bb-bb00-d7aac3394193-c000.snappy.parquet\r\n",
      "└── [   0]  _SUCCESS\r\n",
      "\r\n",
      "0 directories, 13 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -h fhvhv/2021/06/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd09f2",
   "metadata": {},
   "source": [
    "Answer: **24MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7d62b2",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15?</br></br>\n",
    "Consider only trips that started on June 15.</br>\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 50,982\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea78fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/06/*')\n",
    "df.filter(F.to_date('pickup_datetime') == '2021-06-15').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117eded0",
   "metadata": {},
   "source": [
    "Answer: **452,470**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4e165",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>\n",
    "\n",
    "- 66.87 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9dd9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==============>                                         (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|duration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "|              B02872|2021-06-25 13:55:41|2021-06-28 08:48:25|          98|         265|      N|                B02872|  66.879|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn('duration', F.round((F.col('dropoff_datetime').cast(\"long\") - F.col('pickup_datetime').cast(\"long\"))/3600,3)) \\\n",
    "    .orderBy(F.col('duration').desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112c219",
   "metadata": {},
   "source": [
    "Answer: **66.879** Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be15cc",
   "metadata": {},
   "source": [
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    " Spark’s User Interface which shows application's dashboard runs on which local port?</br>\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894b940",
   "metadata": {},
   "source": [
    "Answer: **4040**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae3020",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)</br>\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- Crown Heights North\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e41485c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-07 10:28:31--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230307T082831Z&X-Amz-Expires=300&X-Amz-Signature=b8904e9eacd750459dec06d90e56b0dfe96df95b197cddd2adeb84dfa19f0d17&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-07 10:28:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230307T082831Z&X-Amz-Expires=300&X-Amz-Signature=b8904e9eacd750459dec06d90e56b0dfe96df95b197cddd2adeb84dfa19f0d17&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2023-03-07 10:28:33 (2.75 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c31d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----------+--------+-------------------+------------+\n",
      "|PULocationID| count|LocationID| Borough|               Zone|service_zone|\n",
      "+------------+------+----------+--------+-------------------+------------+\n",
      "|          61|231279|        61|Brooklyn|Crown Heights North|   Boro Zone|\n",
      "+------------+------+----------+--------+-------------------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .csv('taxi_zone_lookup.csv')\n",
    "df.groupBy('PULocationID') \\\n",
    "    .count() \\\n",
    "    .orderBy(F.col('count').desc()) \\\n",
    "    .join(df_zones, df['PULocationID'] == df_zones['LocationID'], how='left').show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70b16d",
   "metadata": {},
   "source": [
    "Answer: **Crown Heights North**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
